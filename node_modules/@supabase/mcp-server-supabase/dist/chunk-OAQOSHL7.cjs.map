{"version":3,"sources":["../package.json","../src/server.ts","../src/management-api/index.ts","../src/tools/branching-tools.ts","../src/pg-meta/columns.sql","../src/pg-meta/extensions.sql","../src/pg-meta/tables.sql","../src/pg-meta/index.ts","../src/tools/database-operation-tools.ts","../src/logs.ts","../src/tools/development-tools.ts","../src/edge-function.ts","../src/tools/edge-function-tools.ts","../src/password.ts"],"names":["package_default","createManagementApiClient","baseUrl","accessToken","headers","createClient","stripIndent"],"mappings":"AAAA,04BAAAA,CAAAA,CAAA,CACE,IAAA,CAAQ,+BAAA,CACR,OAAA,CAAW,OAAA,CACX,WAAA,CAAe,0CAAA,CACf,OAAA,CAAW,YAAA,CACX,IAAA,CAAQ,QAAA,CACR,IAAA,CAAQ,gBAAA,CACR,KAAA,CAAS,iBAAA,CACT,WAAA,CAAe,CAAA,CAAA,CACf,OAAA,CAAW,CACT,KAAA,CAAS,cAAA,CACT,cAAA,CAAkB,eAAA,CAClB,IAAA,CAAQ,QAAA,CACR,UAAA,CAAY,sBAAA,CACZ,WAAA,CAAa,uBAAA,CACb,+BAAA,CAAiC,0FACnC,CAAA,CACA,KAAA,CAAS,CACP,WACF,CAAA,CACA,GAAA,CAAO,CACL,qBAAA,CAAuB,iBACzB,CAAA,CACA,OAAA,CAAW,CACT,GAAA,CAAK,CACH,MAAA,CAAU,iBAAA,CACV,KAAA,CAAS,mBAAA,CACT,OAAA,CAAW,kBACb,CACF,CAAA,CACA,YAAA,CAAgB,CACd,aAAA,CAAe,SAAA,CACf,2BAAA,CAA6B,QAAA,CAC7B,qBAAA,CAAuB,OAAA,CACvB,aAAA,CAAe,QAAA,CACf,eAAA,CAAiB,SAAA,CACjB,GAAA,CAAO,SACT,CAAA,CACA,eAAA,CAAmB,CACjB,mBAAA,CAAqB,QAAA,CACrB,sBAAA,CAAwB,SAAA,CACxB,4BAAA,CAA8B,QAAA,CAC9B,oBAAA,CAAsB,QAAA,CACtB,aAAA,CAAe,SAAA,CACf,EAAA,CAAM,QAAA,CACN,UAAA,CAAY,QAAA,CACZ,MAAA,CAAU,SAAA,CACV,GAAA,CAAO,QAAA,CACP,MAAA,CAAU,QAAA,CACV,oBAAA,CAAsB,QAAA,CACtB,4BAAA,CAA8B,SAAA,CAC9B,QAAA,CAAY,QAAA,CACZ,IAAA,CAAQ,QAAA,CACR,GAAA,CAAO,SAAA,CACP,UAAA,CAAc,QAAA,CACd,MAAA,CAAU,QACZ,CACF,CAAA,CCzDA,+CAA2C,yGCIpC,0BAMW,SAGFC,CAAAA,CACdC,CAAAA,CACAC,CAAAA,CACAC,CAAAA,CAAkC,CAAC,CAAA,CACnC,CACA,OAAOC,oCAAAA,CACL,OAAA,CAAAH,CAAAA,CACA,OAAA,CAAS,CACP,aAAA,CAAe,CAAA,OAAA,EAAUC,CAAW,CAAA,CAAA;ACetB;ACpCpB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ACgBYG;AAAA;AAEgB,iBAAA;AACE,kBAAA;AAAA;AAAA;AAGwC,MAAA;AAAA;AAI7D,EAAA;AAsBAA;AAAA;AAAA;AAAA;AAIyD,gCAAA;AAAA;AAEhD,UAAA;AAAA;AAAA;AAGD,SAAA;AC4CS,EAAA;ACtFb;AAAA;AAAA;AAAA;AAAA;AAAA;AAOQ,cAAA;AAGRA,MAAAA;AAAA;AAAA;AAGQ,cAAA;AAGRA,MAAAA;AAAA;AAAA;AAAA;AAAA;AAKQ,cAAA;AAGRA,MAAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMQ,cAAA;AAGRA,MAAAA;AAAA;AAAA;AAAA;AAIQ,cAAA;AAGRA,MAAAA;AAAA;AAAA;AAGQ,cAAA;AAGRA,MAAAA;AAAA;AAAA;AAGQ,cAAA;ACzBT,MAAA;ACbuB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ACmChB;AAAA;ACrCnB","file":"/Users/grichardson/Documents/dev/supabase/mcp-server-supabase/packages/mcp-server-supabase/dist/chunk-OAQOSHL7.cjs","sourcesContent":["{\n  \"name\": \"@supabase/mcp-server-supabase\",\n  \"version\": \"0.4.0\",\n  \"description\": \"MCP server for interacting with Supabase\",\n  \"license\": \"Apache-2.0\",\n  \"type\": \"module\",\n  \"main\": \"dist/index.cjs\",\n  \"types\": \"dist/index.d.ts\",\n  \"sideEffects\": false,\n  \"scripts\": {\n    \"build\": \"tsup --clean\",\n    \"prepublishOnly\": \"npm run build\",\n    \"test\": \"vitest\",\n    \"test:e2e\": \"vitest --project e2e\",\n    \"test:unit\": \"vitest --project unit\",\n    \"generate:management-api-types\": \"openapi-typescript https://api.supabase.com/api/v1-json -o ./src/management-api/types.ts\"\n  },\n  \"files\": [\n    \"dist/**/*\"\n  ],\n  \"bin\": {\n    \"mcp-server-supabase\": \"./dist/stdio.js\"\n  },\n  \"exports\": {\n    \".\": {\n      \"import\": \"./dist/index.js\",\n      \"types\": \"./dist/index.d.ts\",\n      \"default\": \"./dist/index.cjs\"\n    }\n  },\n  \"dependencies\": {\n    \"@deno/eszip\": \"^0.84.0\",\n    \"@modelcontextprotocol/sdk\": \"^1.4.1\",\n    \"@supabase/mcp-utils\": \"0.2.0\",\n    \"common-tags\": \"^1.8.2\",\n    \"openapi-fetch\": \"^0.13.5\",\n    \"zod\": \"^3.24.1\"\n  },\n  \"devDependencies\": {\n    \"@ai-sdk/anthropic\": \"^1.2.9\",\n    \"@electric-sql/pglite\": \"^0.2.17\",\n    \"@total-typescript/tsconfig\": \"^1.0.4\",\n    \"@types/common-tags\": \"^1.8.4\",\n    \"@types/node\": \"^22.8.6\",\n    \"ai\": \"^4.3.4\",\n    \"date-fns\": \"^4.1.0\",\n    \"dotenv\": \"^16.5.0\",\n    \"msw\": \"^2.7.3\",\n    \"nanoid\": \"^5.1.5\",\n    \"openapi-typescript\": \"^7.5.0\",\n    \"openapi-typescript-helpers\": \"^0.0.15\",\n    \"prettier\": \"^3.3.3\",\n    \"tsup\": \"^8.3.5\",\n    \"tsx\": \"^4.19.2\",\n    \"typescript\": \"^5.6.3\",\n    \"vitest\": \"^2.1.9\"\n  }\n}\n","import { createMcpServer, type Tool } from '@supabase/mcp-utils';\nimport packageJson from '../package.json' with { type: 'json' };\nimport {\n  createManagementApiClient,\n  type ManagementApiClient,\n} from './management-api/index.js';\nimport { getBranchingTools } from './tools/branching-tools.js';\nimport { getDatabaseOperationTools } from './tools/database-operation-tools.js';\nimport { getDebuggingTools } from './tools/debugging-tools.js';\nimport { getDevelopmentTools } from './tools/development-tools.js';\nimport { getEdgeFunctionTools } from './tools/edge-function-tools.js';\nimport { getProjectManagementTools } from './tools/project-management-tools.js';\n\nconst { version } = packageJson;\n\nexport type SupabasePlatformOptions = {\n  /**\n   * The access token for the Supabase Management API.\n   */\n  accessToken: string;\n\n  /**\n   * The API URL for the Supabase Management API.\n   */\n  apiUrl?: string;\n};\n\nexport type SupabaseMcpServerOptions = {\n  /**\n   * Platform options for Supabase.\n   */\n  platform: SupabasePlatformOptions;\n\n  /**\n   * The project ID to scope the server to.\n   *\n   * If undefined, the server will have access\n   * to all organizations and projects for the user.\n   */\n  projectId?: string;\n\n  /**\n   * Executes database queries in read-only mode if true.\n   */\n  readOnly?: boolean;\n};\n\n/**\n * Creates an MCP server for interacting with Supabase.\n */\nexport function createSupabaseMcpServer(options: SupabaseMcpServerOptions) {\n  const managementApiUrl =\n    options.platform.apiUrl ?? 'https://api.supabase.com';\n  const projectId = options.projectId;\n  const readOnly = options.readOnly;\n\n  let managementApiClient: ManagementApiClient;\n\n  const server = createMcpServer({\n    name: 'supabase',\n    version,\n    onInitialize({ clientInfo }) {\n      managementApiClient = createManagementApiClient(\n        managementApiUrl,\n        options.platform.accessToken,\n        {\n          'User-Agent': `supabase-mcp/${version} (${clientInfo.name}/${clientInfo.version})`,\n        }\n      );\n    },\n    tools: () => {\n      const tools: Record<string, Tool> = {};\n\n      // Add account-level tools only if projectId is not provided\n      if (!projectId) {\n        Object.assign(\n          tools,\n          getProjectManagementTools({ managementApiClient })\n        );\n      }\n\n      // Add project-level tools\n      Object.assign(\n        tools,\n        getDatabaseOperationTools({\n          managementApiClient,\n          projectId,\n          readOnly,\n        }),\n        getEdgeFunctionTools({\n          managementApiClient,\n          projectId,\n        }),\n        getDebuggingTools({\n          managementApiClient,\n          projectId,\n        }),\n        getDevelopmentTools({\n          managementApiClient,\n          projectId,\n        }),\n        getBranchingTools({\n          managementApiClient,\n          projectId,\n        })\n      );\n\n      return tools;\n    },\n  });\n\n  return server;\n}\n","import createClient, {\n  type Client,\n  type FetchResponse,\n  type ParseAsResponse,\n} from 'openapi-fetch';\nimport type {\n  MediaType,\n  ResponseObjectMap,\n  SuccessResponse,\n} from 'openapi-typescript-helpers';\nimport { z } from 'zod';\nimport type { paths } from './types.js';\n\nexport function createManagementApiClient(\n  baseUrl: string,\n  accessToken: string,\n  headers: Record<string, string> = {}\n) {\n  return createClient<paths>({\n    baseUrl,\n    headers: {\n      Authorization: `Bearer ${accessToken}`,\n      ...headers,\n    },\n  });\n}\n\nexport type ManagementApiClient = Client<paths>;\n\nexport type SuccessResponseType<\n  T extends Record<string | number, any>,\n  Options,\n  Media extends MediaType,\n> = {\n  data: ParseAsResponse<SuccessResponse<ResponseObjectMap<T>, Media>, Options>;\n  error?: never;\n  response: Response;\n};\n\nconst errorSchema = z.object({\n  message: z.string(),\n});\n\nexport function assertSuccess<\n  T extends Record<string | number, any>,\n  Options,\n  Media extends MediaType,\n>(\n  response: FetchResponse<T, Options, Media>,\n  fallbackMessage: string\n): asserts response is SuccessResponseType<T, Options, Media> {\n  if ('error' in response) {\n    if (response.response.status === 401) {\n      throw new Error(\n        'Unauthorized. Please provide a valid access token to the MCP server via the --access-token flag or SUPABASE_ACCESS_TOKEN.'\n      );\n    }\n\n    const { data: errorContent } = errorSchema.safeParse(response.error);\n\n    if (errorContent) {\n      throw new Error(errorContent.message);\n    }\n\n    throw new Error(fallbackMessage);\n  }\n}\n","import { tool } from '@supabase/mcp-utils';\nimport { z } from 'zod';\nimport {\n  assertSuccess,\n  type ManagementApiClient,\n} from '../management-api/index.js';\nimport { getBranchCost } from '../pricing.js';\nimport { hashObject } from '../util.js';\nimport { injectableTool } from './util.js';\n\nexport type BranchingToolsOptions = {\n  managementApiClient: ManagementApiClient;\n  projectId?: string;\n};\n\nexport function getBranchingTools({\n  managementApiClient,\n  projectId,\n}: BranchingToolsOptions) {\n  const project_id = projectId;\n\n  return {\n    create_branch: injectableTool({\n      description:\n        'Creates a development branch on a Supabase project. This will apply all migrations from the main project to a fresh branch database. Note that production data will not carry over. The branch will get its own project_id via the resulting project_ref. Use this ID to execute queries and migrations on the branch.',\n      parameters: z.object({\n        project_id: z.string(),\n        name: z\n          .string()\n          .default('develop')\n          .describe('Name of the branch to create'),\n        confirm_cost_id: z\n          .string({\n            required_error:\n              'User must confirm understanding of costs before creating a branch.',\n          })\n          .describe('The cost confirmation ID. Call `confirm_cost` first.'),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id, name, confirm_cost_id }) => {\n        const cost = getBranchCost();\n        const costHash = await hashObject(cost);\n        if (costHash !== confirm_cost_id) {\n          throw new Error(\n            'Cost confirmation ID does not match the expected cost of creating a branch.'\n          );\n        }\n\n        const createBranchResponse = await managementApiClient.POST(\n          '/v1/projects/{ref}/branches',\n          {\n            params: {\n              path: {\n                ref: project_id,\n              },\n            },\n            body: {\n              branch_name: name,\n            },\n          }\n        );\n\n        assertSuccess(createBranchResponse, 'Failed to create branch');\n\n        // Creating a default branch means we just enabled branching\n        // TODO: move this logic to API eventually.\n        if (createBranchResponse.data.is_default) {\n          await managementApiClient.PATCH('/v1/branches/{branch_id}', {\n            params: {\n              path: {\n                branch_id: createBranchResponse.data.id,\n              },\n            },\n            body: {\n              branch_name: 'main',\n            },\n          });\n\n          const response = await managementApiClient.POST(\n            '/v1/projects/{ref}/branches',\n            {\n              params: {\n                path: {\n                  ref: project_id,\n                },\n              },\n              body: {\n                branch_name: name,\n              },\n            }\n          );\n\n          assertSuccess(response, 'Failed to create branch');\n\n          return response.data;\n        }\n\n        return createBranchResponse.data;\n      },\n    }),\n    list_branches: injectableTool({\n      description:\n        'Lists all development branches of a Supabase project. This will return branch details including status which you can use to check when operations like merge/rebase/reset complete.',\n      parameters: z.object({\n        project_id: z.string(),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id }) => {\n        const response = await managementApiClient.GET(\n          '/v1/projects/{ref}/branches',\n          {\n            params: {\n              path: {\n                ref: project_id,\n              },\n            },\n          }\n        );\n\n        // There are no branches if branching is disabled\n        if (response.response.status === 422) return [];\n        assertSuccess(response, 'Failed to list branches');\n\n        return response.data;\n      },\n    }),\n    delete_branch: tool({\n      description: 'Deletes a development branch.',\n      parameters: z.object({\n        branch_id: z.string(),\n      }),\n      execute: async ({ branch_id }) => {\n        const response = await managementApiClient.DELETE(\n          '/v1/branches/{branch_id}',\n          {\n            params: {\n              path: {\n                branch_id,\n              },\n            },\n          }\n        );\n\n        assertSuccess(response, 'Failed to delete branch');\n\n        return response.data;\n      },\n    }),\n    merge_branch: tool({\n      description:\n        'Merges migrations and edge functions from a development branch to production.',\n      parameters: z.object({\n        branch_id: z.string(),\n      }),\n      execute: async ({ branch_id }) => {\n        const response = await managementApiClient.POST(\n          '/v1/branches/{branch_id}/merge',\n          {\n            params: {\n              path: {\n                branch_id,\n              },\n            },\n            body: {},\n          }\n        );\n\n        assertSuccess(response, 'Failed to merge branch');\n\n        return response.data;\n      },\n    }),\n    reset_branch: tool({\n      description:\n        'Resets migrations of a development branch. Any untracked data or schema changes will be lost.',\n      parameters: z.object({\n        branch_id: z.string(),\n        migration_version: z\n          .string()\n          .optional()\n          .describe(\n            'Reset your development branch to a specific migration version.'\n          ),\n      }),\n      execute: async ({ branch_id, migration_version }) => {\n        const response = await managementApiClient.POST(\n          '/v1/branches/{branch_id}/reset',\n          {\n            params: {\n              path: {\n                branch_id,\n              },\n            },\n            body: {\n              migration_version,\n            },\n          }\n        );\n\n        assertSuccess(response, 'Failed to reset branch');\n\n        return response.data;\n      },\n    }),\n    rebase_branch: tool({\n      description:\n        'Rebases a development branch on production. This will effectively run any newer migrations from production onto this branch to help handle migration drift.',\n      parameters: z.object({\n        branch_id: z.string(),\n      }),\n      execute: async ({ branch_id }) => {\n        const response = await managementApiClient.POST(\n          '/v1/branches/{branch_id}/push',\n          {\n            params: {\n              path: {\n                branch_id,\n              },\n            },\n            body: {},\n          }\n        );\n\n        assertSuccess(response, 'Failed to rebase branch');\n\n        return response.data;\n      },\n    }),\n  };\n}\n","-- Adapted from information_schema.columns\n\nSELECT\n  c.oid :: int8 AS table_id,\n  nc.nspname AS schema,\n  c.relname AS table,\n  (c.oid || '.' || a.attnum) AS id,\n  a.attnum AS ordinal_position,\n  a.attname AS name,\n  CASE\n    WHEN a.atthasdef THEN pg_get_expr(ad.adbin, ad.adrelid)\n    ELSE NULL\n  END AS default_value,\n  CASE\n    WHEN t.typtype = 'd' THEN CASE\n      WHEN bt.typelem <> 0 :: oid\n      AND bt.typlen = -1 THEN 'ARRAY'\n      WHEN nbt.nspname = 'pg_catalog' THEN format_type(t.typbasetype, NULL)\n      ELSE 'USER-DEFINED'\n    END\n    ELSE CASE\n      WHEN t.typelem <> 0 :: oid\n      AND t.typlen = -1 THEN 'ARRAY'\n      WHEN nt.nspname = 'pg_catalog' THEN format_type(a.atttypid, NULL)\n      ELSE 'USER-DEFINED'\n    END\n  END AS data_type,\n  COALESCE(bt.typname, t.typname) AS format,\n  a.attidentity IN ('a', 'd') AS is_identity,\n  CASE\n    a.attidentity\n    WHEN 'a' THEN 'ALWAYS'\n    WHEN 'd' THEN 'BY DEFAULT'\n    ELSE NULL\n  END AS identity_generation,\n  a.attgenerated IN ('s') AS is_generated,\n  NOT (\n    a.attnotnull\n    OR t.typtype = 'd' AND t.typnotnull\n  ) AS is_nullable,\n  (\n    c.relkind IN ('r', 'p')\n    OR c.relkind IN ('v', 'f') AND pg_column_is_updatable(c.oid, a.attnum, FALSE)\n  ) AS is_updatable,\n  uniques.table_id IS NOT NULL AS is_unique,\n  check_constraints.definition AS \"check\",\n  array_to_json(\n    array(\n      SELECT\n        enumlabel\n      FROM\n        pg_catalog.pg_enum enums\n      WHERE\n        enums.enumtypid = coalesce(bt.oid, t.oid)\n        OR enums.enumtypid = coalesce(bt.typelem, t.typelem)\n      ORDER BY\n        enums.enumsortorder\n    )\n  ) AS enums,\n  col_description(c.oid, a.attnum) AS comment\nFROM\n  pg_attribute a\n  LEFT JOIN pg_attrdef ad ON a.attrelid = ad.adrelid\n  AND a.attnum = ad.adnum\n  JOIN (\n    pg_class c\n    JOIN pg_namespace nc ON c.relnamespace = nc.oid\n  ) ON a.attrelid = c.oid\n  JOIN (\n    pg_type t\n    JOIN pg_namespace nt ON t.typnamespace = nt.oid\n  ) ON a.atttypid = t.oid\n  LEFT JOIN (\n    pg_type bt\n    JOIN pg_namespace nbt ON bt.typnamespace = nbt.oid\n  ) ON t.typtype = 'd'\n  AND t.typbasetype = bt.oid\n  LEFT JOIN (\n    SELECT DISTINCT ON (table_id, ordinal_position)\n      conrelid AS table_id,\n      conkey[1] AS ordinal_position\n    FROM pg_catalog.pg_constraint\n    WHERE contype = 'u' AND cardinality(conkey) = 1\n  ) AS uniques ON uniques.table_id = c.oid AND uniques.ordinal_position = a.attnum\n  LEFT JOIN (\n    -- We only select the first column check\n    SELECT DISTINCT ON (table_id, ordinal_position)\n      conrelid AS table_id,\n      conkey[1] AS ordinal_position,\n      substring(\n        pg_get_constraintdef(pg_constraint.oid, true),\n        8,\n        length(pg_get_constraintdef(pg_constraint.oid, true)) - 8\n      ) AS \"definition\"\n    FROM pg_constraint\n    WHERE contype = 'c' AND cardinality(conkey) = 1\n    ORDER BY table_id, ordinal_position, oid asc\n  ) AS check_constraints ON check_constraints.table_id = c.oid AND check_constraints.ordinal_position = a.attnum\nWHERE\n  NOT pg_is_other_temp_schema(nc.oid)\n  AND a.attnum > 0\n  AND NOT a.attisdropped\n  AND (c.relkind IN ('r', 'v', 'm', 'f', 'p'))\n  AND (\n    pg_has_role(c.relowner, 'USAGE')\n    OR has_column_privilege(\n      c.oid,\n      a.attnum,\n      'SELECT, INSERT, UPDATE, REFERENCES'\n    )\n  )\n","SELECT\n  e.name,\n  n.nspname AS schema,\n  e.default_version,\n  x.extversion AS installed_version,\n  e.comment\nFROM\n  pg_available_extensions() e(name, default_version, comment)\n  LEFT JOIN pg_extension x ON e.name = x.extname\n  LEFT JOIN pg_namespace n ON x.extnamespace = n.oid\n","SELECT\n  c.oid :: int8 AS id,\n  nc.nspname AS schema,\n  c.relname AS name,\n  c.relrowsecurity AS rls_enabled,\n  c.relforcerowsecurity AS rls_forced,\n  CASE\n    WHEN c.relreplident = 'd' THEN 'DEFAULT'\n    WHEN c.relreplident = 'i' THEN 'INDEX'\n    WHEN c.relreplident = 'f' THEN 'FULL'\n    ELSE 'NOTHING'\n  END AS replica_identity,\n  pg_total_relation_size(format('%I.%I', nc.nspname, c.relname)) :: int8 AS bytes,\n  pg_size_pretty(\n    pg_total_relation_size(format('%I.%I', nc.nspname, c.relname))\n  ) AS size,\n  pg_stat_get_live_tuples(c.oid) AS live_rows_estimate,\n  pg_stat_get_dead_tuples(c.oid) AS dead_rows_estimate,\n  obj_description(c.oid) AS comment,\n  coalesce(pk.primary_keys, '[]') as primary_keys,\n  coalesce(\n    jsonb_agg(relationships) filter (where relationships is not null),\n    '[]'\n  ) as relationships\nFROM\n  pg_namespace nc\n  JOIN pg_class c ON nc.oid = c.relnamespace\n  left join (\n    select\n      table_id,\n      jsonb_agg(_pk.*) as primary_keys\n    from (\n      select\n        n.nspname as schema,\n        c.relname as table_name,\n        a.attname as name,\n        c.oid :: int8 as table_id\n      from\n        pg_index i,\n        pg_class c,\n        pg_attribute a,\n        pg_namespace n\n      where\n        i.indrelid = c.oid\n        and c.relnamespace = n.oid\n        and a.attrelid = c.oid\n        and a.attnum = any (i.indkey)\n        and i.indisprimary\n    ) as _pk\n    group by table_id\n  ) as pk\n  on pk.table_id = c.oid\n  left join (\n    select\n      c.oid :: int8 as id,\n      c.conname as constraint_name,\n      nsa.nspname as source_schema,\n      csa.relname as source_table_name,\n      sa.attname as source_column_name,\n      nta.nspname as target_table_schema,\n      cta.relname as target_table_name,\n      ta.attname as target_column_name\n    from\n      pg_constraint c\n    join (\n      pg_attribute sa\n      join pg_class csa on sa.attrelid = csa.oid\n      join pg_namespace nsa on csa.relnamespace = nsa.oid\n    ) on sa.attrelid = c.conrelid and sa.attnum = any (c.conkey)\n    join (\n      pg_attribute ta\n      join pg_class cta on ta.attrelid = cta.oid\n      join pg_namespace nta on cta.relnamespace = nta.oid\n    ) on ta.attrelid = c.confrelid and ta.attnum = any (c.confkey)\n    where\n      c.contype = 'f'\n  ) as relationships\n  on (relationships.source_schema = nc.nspname and relationships.source_table_name = c.relname)\n  or (relationships.target_table_schema = nc.nspname and relationships.target_table_name = c.relname)\nWHERE\n  c.relkind IN ('r', 'p')\n  AND NOT pg_is_other_temp_schema(nc.oid)\n  AND (\n    pg_has_role(c.relowner, 'USAGE')\n    OR has_table_privilege(\n      c.oid,\n      'SELECT, INSERT, UPDATE, DELETE, TRUNCATE, REFERENCES, TRIGGER'\n    )\n    OR has_any_column_privilege(c.oid, 'SELECT, INSERT, UPDATE, REFERENCES')\n  )\ngroup by\n  c.oid,\n  c.relname,\n  c.relrowsecurity,\n  c.relforcerowsecurity,\n  c.relreplident,\n  nc.nspname,\n  pk.primary_keys\n","import { stripIndent } from 'common-tags';\nimport columnsSql from './columns.sql';\nimport extensionsSql from './extensions.sql';\nimport tablesSql from './tables.sql';\n\nexport const SYSTEM_SCHEMAS = [\n  'information_schema',\n  'pg_catalog',\n  'pg_toast',\n  '_timescaledb_internal',\n];\n\n/**\n * Generates the SQL query to list tables in the database.\n */\nexport function listTablesSql(schemas: string[] = []) {\n  let sql = stripIndent`\n    with\n      tables as (${tablesSql}),\n      columns as (${columnsSql})\n    select\n      *,\n      ${coalesceRowsToArray('columns', 'columns.table_id = tables.id')}\n    from tables\n  `;\n\n  sql += '\\n';\n\n  if (schemas.length > 0) {\n    sql += `where schema in (${schemas.map((s) => `'${s}'`).join(',')})`;\n  } else {\n    sql += `where schema not in (${SYSTEM_SCHEMAS.map((s) => `'${s}'`).join(',')})`;\n  }\n\n  return sql;\n}\n\n/**\n * Generates the SQL query to list all extensions in the database.\n */\nexport function listExtensionsSql() {\n  return extensionsSql;\n}\n\n/**\n * Generates a SQL segment that coalesces rows into an array of JSON objects.\n */\nexport const coalesceRowsToArray = (source: string, filter: string) => {\n  return stripIndent`\n    COALESCE(\n      (\n        SELECT\n          array_agg(row_to_json(${source})) FILTER (WHERE ${filter})\n        FROM\n          ${source}\n      ),\n      '{}'\n    ) AS ${source}\n  `;\n};\n","import { z } from 'zod';\nimport {\n  assertSuccess,\n  type ManagementApiClient,\n} from '../management-api/index.js';\nimport { listExtensionsSql, listTablesSql } from '../pg-meta/index.js';\nimport type { PostgresExtension, PostgresTable } from '../pg-meta/types.js';\nimport { injectableTool } from './util.js';\n\nexport type DatabaseOperationToolsOptions = {\n  managementApiClient: ManagementApiClient;\n  projectId?: string;\n  readOnly?: boolean;\n};\n\nexport function getDatabaseOperationTools({\n  managementApiClient,\n  projectId,\n  readOnly,\n}: DatabaseOperationToolsOptions) {\n  async function executeSql<T>(projectId: string, query: string): Promise<T[]> {\n    const response = await managementApiClient.POST(\n      '/v1/projects/{ref}/database/query',\n      {\n        params: {\n          path: {\n            ref: projectId,\n          },\n        },\n        body: {\n          query,\n          read_only: readOnly,\n        },\n      }\n    );\n\n    assertSuccess(response, 'Failed to execute SQL query');\n\n    return response.data as unknown as T[];\n  }\n\n  const project_id = projectId;\n\n  const databaseOperationTools = {\n    list_tables: injectableTool({\n      description: 'Lists all tables in one or more schemas.',\n      parameters: z.object({\n        project_id: z.string(),\n        schemas: z\n          .array(z.string())\n          .describe('List of schemas to include. Defaults to all schemas.')\n          .default(['public']),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id, schemas }) => {\n        const sql = listTablesSql(schemas);\n        const data = await executeSql<PostgresTable>(project_id, sql);\n        return data;\n      },\n    }),\n    list_extensions: injectableTool({\n      description: 'Lists all extensions in the database.',\n      parameters: z.object({\n        project_id: z.string(),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id }) => {\n        const sql = listExtensionsSql();\n        const data = await executeSql<PostgresExtension>(project_id, sql);\n        return data;\n      },\n    }),\n    list_migrations: injectableTool({\n      description: 'Lists all migrations in the database.',\n      parameters: z.object({\n        project_id: z.string(),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id }) => {\n        const response = await managementApiClient.GET(\n          '/v1/projects/{ref}/database/migrations',\n          {\n            params: {\n              path: {\n                ref: project_id,\n              },\n            },\n          }\n        );\n\n        assertSuccess(response, 'Failed to fetch migrations');\n\n        return response.data;\n      },\n    }),\n    apply_migration: injectableTool({\n      description:\n        'Applies a migration to the database. Use this when executing DDL operations. Do not hardcode references to generated IDs in data migrations.',\n      parameters: z.object({\n        project_id: z.string(),\n        name: z.string().describe('The name of the migration in snake_case'),\n        query: z.string().describe('The SQL query to apply'),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id, name, query }) => {\n        if (readOnly) {\n          throw new Error('Cannot apply migration in read-only mode.');\n        }\n\n        const response = await managementApiClient.POST(\n          '/v1/projects/{ref}/database/migrations',\n          {\n            params: {\n              path: {\n                ref: project_id,\n              },\n            },\n            body: {\n              name,\n              query,\n            },\n          }\n        );\n\n        assertSuccess(response, 'Failed to apply migration');\n\n        return response.data;\n      },\n    }),\n    execute_sql: injectableTool({\n      description:\n        'Executes raw SQL in the Postgres database. Use `apply_migration` instead for DDL operations.',\n      parameters: z.object({\n        project_id: z.string(),\n        query: z.string().describe('The SQL query to execute'),\n      }),\n      inject: { project_id },\n      execute: async ({ query, project_id }) => {\n        return await executeSql(project_id, query);\n      },\n    }),\n  };\n\n  type test = z.infer<\n    (typeof databaseOperationTools)['list_tables']['parameters']\n  >;\n\n  return databaseOperationTools;\n}\n","import { stripIndent } from 'common-tags';\n\nexport function getLogQuery(\n  service:\n    | 'api'\n    | 'branch-action'\n    | 'postgres'\n    | 'edge-function'\n    | 'auth'\n    | 'storage'\n    | 'realtime',\n  limit: number = 100\n) {\n  switch (service) {\n    case 'api':\n      return stripIndent`\n        select id, identifier, timestamp, event_message, request.method, request.path, response.status_code\n        from edge_logs\n        cross join unnest(metadata) as m\n        cross join unnest(m.request) as request\n        cross join unnest(m.response) as response\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'branch-action':\n      return stripIndent`\n        select workflow_run, workflow_run_logs.timestamp, id, event_message from workflow_run_logs\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'postgres':\n      return stripIndent`\n        select identifier, postgres_logs.timestamp, id, event_message, parsed.error_severity from postgres_logs\n        cross join unnest(metadata) as m\n        cross join unnest(m.parsed) as parsed\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'edge-function':\n      return stripIndent`\n        select id, function_edge_logs.timestamp, event_message, response.status_code, request.method, m.function_id, m.execution_time_ms, m.deployment_id, m.version from function_edge_logs\n        cross join unnest(metadata) as m\n        cross join unnest(m.response) as response\n        cross join unnest(m.request) as request\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'auth':\n      return stripIndent`\n        select id, auth_logs.timestamp, event_message, metadata.level, metadata.status, metadata.path, metadata.msg as msg, metadata.error from auth_logs\n        cross join unnest(metadata) as metadata\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'storage':\n      return stripIndent`\n        select id, storage_logs.timestamp, event_message from storage_logs\n        order by timestamp desc\n        limit ${limit}\n      `;\n    case 'realtime':\n      return stripIndent`\n        select id, realtime_logs.timestamp, event_message from realtime_logs\n        order by timestamp desc\n        limit ${limit}\n      `;\n    default:\n      throw new Error(`unsupported log service type: ${service}`);\n  }\n}\n","import { z } from 'zod';\nimport {\n  assertSuccess,\n  type ManagementApiClient,\n} from '../management-api/index.js';\nimport { injectableTool } from './util.js';\n\nexport type DevelopmentToolsOptions = {\n  managementApiClient: ManagementApiClient;\n  projectId?: string;\n};\n\nexport function getDevelopmentTools({\n  managementApiClient,\n  projectId,\n}: DevelopmentToolsOptions) {\n  const project_id = projectId;\n\n  return {\n    get_project_url: injectableTool({\n      description: 'Gets the API URL for a project.',\n      parameters: z.object({\n        project_id: z.string(),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id }) => {\n        return `https://${project_id}.supabase.co`;\n      },\n    }),\n    get_anon_key: injectableTool({\n      description: 'Gets the anonymous API key for a project.',\n      parameters: z.object({\n        project_id: z.string(),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id }) => {\n        const response = await managementApiClient.GET(\n          '/v1/projects/{ref}/api-keys',\n          {\n            params: {\n              path: {\n                ref: project_id,\n              },\n              query: {\n                reveal: false,\n              },\n            },\n          }\n        );\n\n        assertSuccess(response, 'Failed to fetch API keys');\n\n        const anonKey = response.data?.find((key) => key.name === 'anon');\n\n        if (!anonKey) {\n          throw new Error('Anonymous key not found');\n        }\n\n        return anonKey.api_key;\n      },\n    }),\n    generate_typescript_types: injectableTool({\n      description: 'Generates TypeScript types for a project.',\n      parameters: z.object({\n        project_id: z.string(),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id }) => {\n        const response = await managementApiClient.GET(\n          '/v1/projects/{ref}/types/typescript',\n          {\n            params: {\n              path: {\n                ref: project_id,\n              },\n            },\n          }\n        );\n\n        assertSuccess(response, 'Failed to fetch TypeScript types');\n\n        return response.data;\n      },\n    }),\n  };\n}\n","import { codeBlock } from 'common-tags';\nimport { fileURLToPath } from 'url';\nimport { extractFiles } from './eszip.js';\nimport {\n  assertSuccess,\n  type ManagementApiClient,\n} from './management-api/index.js';\n\n/**\n * Gets the deployment ID for an Edge Function.\n */\nexport function getDeploymentId(\n  projectId: string,\n  functionId: string,\n  functionVersion: number\n): string {\n  return `${projectId}_${functionId}_${functionVersion}`;\n}\n\n/**\n * Gets the path prefix applied to each file in an Edge Function.\n */\nexport function getPathPrefix(deploymentId: string) {\n  return `/tmp/user_fn_${deploymentId}/`;\n}\n\nexport const edgeFunctionExample = codeBlock`\n  import \"jsr:@supabase/functions-js/edge-runtime.d.ts\";\n\n  Deno.serve(async (req: Request) => {\n    const data = {\n      message: \"Hello there!\"\n    };\n    \n    return new Response(JSON.stringify(data), {\n      headers: {\n        'Content-Type': 'application/json',\n        'Connection': 'keep-alive'\n      }\n    });\n  });\n`;\n\n/**\n * Fetches a full Edge Function from the Supabase Management API.\n\n * - Includes both function metadata and the contents of each file.\n * - Normalizes file paths to be relative to the project root.\n */\nexport async function getFullEdgeFunction(\n  managementApiClient: ManagementApiClient,\n  projectId: string,\n  functionSlug: string\n) {\n  const functionResponse = await managementApiClient.GET(\n    '/v1/projects/{ref}/functions/{function_slug}',\n    {\n      params: {\n        path: {\n          ref: projectId,\n          function_slug: functionSlug,\n        },\n      },\n    }\n  );\n\n  if (functionResponse.error) {\n    return {\n      data: undefined,\n      error: functionResponse.error as { message: string },\n    };\n  }\n\n  assertSuccess(functionResponse, 'Failed to fetch Edge Function');\n\n  const edgeFunction = functionResponse.data;\n\n  const deploymentId = getDeploymentId(\n    projectId,\n    edgeFunction.id,\n    edgeFunction.version\n  );\n\n  const pathPrefix = getPathPrefix(deploymentId);\n\n  const entrypoint_path = edgeFunction.entrypoint_path\n    ? fileURLToPath(edgeFunction.entrypoint_path).replace(pathPrefix, '')\n    : undefined;\n\n  const import_map_path = edgeFunction.import_map_path\n    ? fileURLToPath(edgeFunction.import_map_path).replace(pathPrefix, '')\n    : undefined;\n\n  const eszipResponse = await managementApiClient.GET(\n    '/v1/projects/{ref}/functions/{function_slug}/body',\n    {\n      params: {\n        path: {\n          ref: projectId,\n          function_slug: functionSlug,\n        },\n      },\n      parseAs: 'arrayBuffer',\n    }\n  );\n\n  assertSuccess(eszipResponse, 'Failed to fetch Edge Function eszip bundle');\n\n  const extractedFiles = await extractFiles(\n    new Uint8Array(eszipResponse.data),\n    pathPrefix\n  );\n\n  const files = await Promise.all(\n    extractedFiles.map(async (file) => ({\n      name: file.name,\n      content: await file.text(),\n    }))\n  );\n\n  const normalizedFunction = {\n    ...edgeFunction,\n    entrypoint_path,\n    import_map_path,\n    files,\n  };\n\n  return { data: normalizedFunction, error: undefined };\n}\n","import { z } from 'zod';\nimport { edgeFunctionExample, getFullEdgeFunction } from '../edge-function.js';\nimport {\n  assertSuccess,\n  type ManagementApiClient,\n} from '../management-api/index.js';\nimport { injectableTool } from './util.js';\n\nexport type EdgeFunctionToolsOptions = {\n  managementApiClient: ManagementApiClient;\n  projectId?: string;\n};\n\nexport function getEdgeFunctionTools({\n  managementApiClient,\n  projectId,\n}: EdgeFunctionToolsOptions) {\n  const project_id = projectId;\n\n  return {\n    list_edge_functions: injectableTool({\n      description: 'Lists all Edge Functions in a Supabase project.',\n      parameters: z.object({\n        project_id: z.string(),\n      }),\n      inject: { project_id },\n      execute: async ({ project_id }) => {\n        const response = await managementApiClient.GET(\n          '/v1/projects/{ref}/functions',\n          {\n            params: {\n              path: {\n                ref: project_id,\n              },\n            },\n          }\n        );\n\n        assertSuccess(response, 'Failed to fetch Edge Functions');\n\n        // Fetch files for each Edge Function\n        const edgeFunctions = await Promise.all(\n          response.data.map(async (listedFunction) => {\n            const { data: edgeFunction, error } = await getFullEdgeFunction(\n              managementApiClient,\n              project_id,\n              listedFunction.slug\n            );\n\n            if (error) {\n              throw error;\n            }\n\n            return edgeFunction;\n          })\n        );\n\n        return edgeFunctions;\n      },\n    }),\n    deploy_edge_function: injectableTool({\n      description: `Deploys an Edge Function to a Supabase project. If the function already exists, this will create a new version. Example:\\n\\n${edgeFunctionExample}`,\n      parameters: z.object({\n        project_id: z.string(),\n        name: z.string().describe('The name of the function'),\n        entrypoint_path: z\n          .string()\n          .default('index.ts')\n          .describe('The entrypoint of the function'),\n        import_map_path: z\n          .string()\n          .describe('The import map for the function.')\n          .optional(),\n        files: z\n          .array(\n            z.object({\n              name: z.string(),\n              content: z.string(),\n            })\n          )\n          .describe(\n            'The files to upload. This should include the entrypoint and any relative dependencies.'\n          ),\n      }),\n      inject: { project_id },\n      execute: async ({\n        project_id,\n        name,\n        entrypoint_path,\n        import_map_path,\n        files,\n      }) => {\n        const { data: existingEdgeFunction } = await getFullEdgeFunction(\n          managementApiClient,\n          project_id,\n          name\n        );\n\n        const import_map_file = files.find((file) =>\n          ['deno.json', 'import_map.json'].includes(file.name)\n        );\n\n        // Use existing import map path or file name heuristic if not provided\n        import_map_path ??=\n          existingEdgeFunction?.import_map_path ?? import_map_file?.name;\n\n        const response = await managementApiClient.POST(\n          '/v1/projects/{ref}/functions/deploy',\n          {\n            params: {\n              path: {\n                ref: project_id,\n              },\n              query: { slug: name },\n            },\n            body: {\n              metadata: {\n                name,\n                entrypoint_path,\n                import_map_path,\n              },\n              file: files as any, // We need to pass file name and content to our serializer\n            },\n            bodySerializer(body) {\n              const formData = new FormData();\n\n              const blob = new Blob([JSON.stringify(body.metadata)], {\n                type: 'application/json',\n              });\n              formData.append('metadata', blob);\n\n              body.file?.forEach((f: any) => {\n                const file: { name: string; content: string } = f;\n                const blob = new Blob([file.content], {\n                  type: 'application/typescript',\n                });\n                formData.append('file', blob, file.name);\n              });\n\n              return formData;\n            },\n          }\n        );\n\n        assertSuccess(response, 'Failed to deploy Edge Function');\n\n        return response.data;\n      },\n    }),\n  };\n}\n","const UPPERCASE_CHARS = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ';\nconst LOWERCASE_CHARS = 'abcdefghijklmnopqrstuvwxyz';\nconst NUMBER_CHARS = '0123456789';\nconst SYMBOL_CHARS = '!@#$%^&*()_+~`|}{[]:;?><,./-=';\n\nexport type GeneratePasswordOptions = {\n  length?: number;\n  numbers?: boolean;\n  uppercase?: boolean;\n  lowercase?: boolean;\n  symbols?: boolean;\n};\n\n/**\n * Generates a cryptographically secure random password.\n *\n * @returns The generated password\n */\nexport const generatePassword = ({\n  length = 10,\n  numbers = false,\n  symbols = false,\n  uppercase = true,\n  lowercase = true,\n} = {}) => {\n  // Build the character set based on options\n  let chars = '';\n  if (uppercase) {\n    chars += UPPERCASE_CHARS;\n  }\n  if (lowercase) {\n    chars += LOWERCASE_CHARS;\n  }\n  if (numbers) {\n    chars += NUMBER_CHARS;\n  }\n  if (symbols) {\n    chars += SYMBOL_CHARS;\n  }\n\n  if (chars.length === 0) {\n    throw new Error('at least one character set must be selected');\n  }\n\n  const randomValues = new Uint32Array(length);\n  crypto.getRandomValues(randomValues);\n\n  // Map random values to our character set\n  let password = '';\n  for (let i = 0; i < length; i++) {\n    const randomIndex = randomValues[i]! % chars.length;\n    password += chars.charAt(randomIndex);\n  }\n\n  return password;\n};\n"]}